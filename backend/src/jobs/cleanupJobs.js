const cron = require('node-cron');
const mongoose = require('mongoose');
const fs = require('fs').promises;
const path = require('path');
const logger = require('../utils/logger');
const redisClient = require('../config/redis');
const { TIME_CONSTANTS } = require('../utils/constants');

class CleanupJobs {
    constructor() {
        this.isRunning = false;
        this.cleanupConfig = {
            logRetentionDays: parseInt(process.env.LOG_RETENTION_DAYS) || 30,
            sessionRetentionDays: parseInt(process.env.SESSION_RETENTION_DAYS) || 7,
            tempFileRetentionHours: parseInt(process.env.TEMP_FILE_RETENTION_HOURS) || 24,
            deletedDataRetentionDays: parseInt(process.env.DELETED_DATA_RETENTION_DAYS) || 90,
            analyticsRetentionDays: parseInt(process.env.ANALYTICS_RETENTION_DAYS) || 365
        };
    }

    /**
     * Kh·ªüi t·∫°o cleanup jobs
     */
    async initialize() {
        try {
            // D·ªçn d·∫πp file t·∫°m m·ªói gi·ªù
            cron.schedule('0 * * * *', async () => {
                await this.cleanupTempFiles();
            });

            // D·ªçn d·∫πp session h·∫øt h·∫°n m·ªói 6 gi·ªù
            cron.schedule('0 */6 * * *', async () => {
                await this.cleanupExpiredSessions();
            });

            // D·ªçn d·∫πp logs c≈© h√†ng ng√†y l√∫c 1 AM
            cron.schedule('0 1 * * *', async () => {
                await this.cleanupOldLogs();
            }, {
                timezone: 'Asia/Ho_Chi_Minh'
            });

            // D·ªçn d·∫πp d·ªØ li·ªáu ƒë√£ x√≥a m·ªÅm h√†ng tu·∫ßn
            cron.schedule('0 2 * * 0', async () => {
                await this.cleanupSoftDeletedData();
            }, {
                timezone: 'Asia/Ho_Chi_Minh'
            });

            // D·ªçn d·∫πp cache Redis h√†ng ng√†y l√∫c 3 AM
            cron.schedul
            e('0 3 * * *', async () => {
                await this.cleanupRedisCache();
            }, {
                timezone: 'Asia/Ho_Chi_Minh'
            });

            // D·ªçn d·∫πp file uploads kh√¥ng s·ª≠ d·ª•ng h√†ng tu·∫ßn
            cron.schedule('0 4 * * 0', async () => {
                await this.cleanupOrphanedFiles();
            }, {
                timezone: 'Asia/Ho_Chi_Minh'
            });

            // D·ªçn d·∫πp analytics data c≈© h√†ng th√°ng
            cron.schedule('0 5 1 * *', async () => {
                await this.cleanupOldAnalytics();
            }, {
                timezone: 'Asia/Ho_Chi_Minh'
            });

            // T·ªëi ∆∞u database h√†ng tu·∫ßn
            cron.schedule('0 6 * * 0', async () => {
                await this.optimizeDatabase();
            }, {
                timezone: 'Asia/Ho_Chi_Minh'
            });

            logger.info('Cleanup jobs ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng');
        } catch (error) {
            logger.error('Kh√¥ng th·ªÉ kh·ªüi t·∫°o cleanup jobs:', error);
            throw error;
        }
    }

    /**
     * D·ªçn d·∫πp file t·∫°m th·ªùi
     */
    async cleanupTempFiles() {
        if (this.isRunning) return;

        try {
            logger.info('B·∫Øt ƒë·∫ßu d·ªçn d·∫πp file t·∫°m...');

            const tempDirs = [
                './uploads/temp',
                './uploads/processing',
                './temp',
                './cache/temp'
            ];

            let totalDeleted = 0;
            let totalSize = 0;
            const cutoffTime = Date.now() - (this.cleanupConfig.tempFileRetentionHours * TIME_CONSTANTS.HOUR);

            for (const tempDir of tempDirs) {
                try {
                    await fs.access(tempDir);
                    const { deleted, size } = await this.cleanupDirectory(tempDir, cutoffTime);
                    totalDeleted += deleted;
                    totalSize += size;
                } catch (error) {
                    if (error.code !== 'ENOENT') {
                        logger.warn(`Kh√¥ng th·ªÉ truy c·∫≠p th∆∞ m·ª•c ${tempDir}:`, error.message);
                    }
                }
            }

            if (totalDeleted > 0) {
                logger.info(`ƒê√£ d·ªçn d·∫πp ${totalDeleted} file t·∫°m, gi·∫£i ph√≥ng ${this.formatBytes(totalSize)}`);
            }

        } catch (error) {
            logger.error('D·ªçn d·∫πp file t·∫°m th·∫•t b·∫°i:', error);
        }
    }

    /**
     * D·ªçn d·∫πp session h·∫øt h·∫°n
     */
    async cleanupExpiredSessions() {
        try {
            logger.info('B·∫Øt ƒë·∫ßu d·ªçn d·∫πp session h·∫øt h·∫°n...');

            const Session = require('../models/Session');
            const cutoffTime = new Date(Date.now() - (this.cleanupConfig.sessionRetentionDays * TIME_CONSTANTS.DAY));

            // X√≥a session h·∫øt h·∫°n
            const expiredSessions = await Session.deleteMany({
                $or: [
                    { expiresAt: { $lt: new Date() } },
                    { lastAccessed: { $lt: cutoffTime } },
                    { isActive: false }
                ]
            });

            // D·ªçn d·∫πp Redis session data
            const pattern = 'sess:*';
            const keys = await redisClient.keys(pattern);
            let deletedRedisKeys = 0;

            for (const key of keys) {
                try {
                    const ttl = await redisClient.ttl(key);
                    if (ttl === -1 || ttl === 0) { // Key h·∫øt h·∫°n ho·∫∑c kh√¥ng c√≥ TTL
                        await redisClient.del(key);
                        deletedRedisKeys++;
                    }
                } catch (error) {
                    logger.warn(`L·ªói ki·ªÉm tra Redis key ${key}:`, error.message);
                }
            }

            logger.info(`ƒê√£ d·ªçn d·∫πp ${expiredSessions.deletedCount} session DB v√† ${deletedRedisKeys} Redis keys`);

        } catch (error) {
            logger.error('D·ªçn d·∫πp session th·∫•t b·∫°i:', error);
        }
    }

    /**
     * D·ªçn d·∫πp logs c≈©
     */
    async cleanupOldLogs() {
        try {
            logger.info('B·∫Øt ƒë·∫ßu d·ªçn d·∫πp logs c≈©...');

            // D·ªçn d·∫πp file logs
            const logDirs = [
                './logs',
                process.env.LOG_FILE_PATH
            ].filter(Boolean);

            let totalDeleted = 0;
            let totalSize = 0;
            const cutoffTime = Date.now() - (this.cleanupConfig.logRetentionDays * TIME_CONSTANTS.DAY);

            for (const logDir of logDirs) {
                try {
                    await fs.access(logDir);
                    const { deleted, size } = await this.cleanupDirectory(logDir, cutoffTime, /\.log$/);
                    totalDeleted += deleted;
                    totalSize += size;
                } catch (error) {
                    if (error.code !== 'ENOENT') {
                        logger.warn(`Kh√¥ng th·ªÉ truy c·∫≠p log directory ${logDir}:`, error.message);
                    }
                }
            }

            // D·ªçn d·∫πp logs trong database
            const SystemLog = require('../models/SystemLog');
            const oldLogs = await SystemLog.deleteMany({
                createdAt: { $lt: new Date(cutoffTime) }
            });

            // D·ªçn d·∫πp error logs
            const ErrorLog = require('../models/ErrorLog');
            const oldErrors = await ErrorLog.deleteMany({
                createdAt: { $lt: new Date(cutoffTime) },
                resolved: true
            });

            logger.info(`ƒê√£ d·ªçn d·∫πp ${totalDeleted} log files (${this.formatBytes(totalSize)}), ${oldLogs.deletedCount} system logs, ${oldErrors.deletedCount} error logs`);

        } catch (error) {
            logger.error('D·ªçn d·∫πp logs th·∫•t b·∫°i:', error);
        }
    }

    /**
     * D·ªçn d·∫πp d·ªØ li·ªáu ƒë√£ x√≥a m·ªÅm
     */
    async cleanupSoftDeletedData() {
        if (this.isRunning) return;
        this.isRunning = true;

        try {
            logger.info('B·∫Øt ƒë·∫ßu d·ªçn d·∫πp d·ªØ li·ªáu ƒë√£ x√≥a m·ªÅm...');

            const cutoffTime = new Date(Date.now() - (this.cleanupConfig.deletedDataRetentionDays * TIME_CONSTANTS.DAY));

            // D·ªçn d·∫πp events ƒë√£ x√≥a
            const Event = require('../models/Event');
            const deletedEvents = await Event.deleteMany({
                isDeleted: true,
                deletedAt: { $lt: cutoffTime }
            });

            // D·ªçn d·∫πp users ƒë√£ x√≥a
            const User = require('../models/User');
            const deletedUsers = await User.deleteMany({
                isDeleted: true,
                deletedAt: { $lt: cutoffTime }
            });

            // D·ªçn d·∫πp registrations c·ªßa events ƒë√£ x√≥a
            const Registration = require('../models/Registration');
            const orphanedRegistrations = await Registration.deleteMany({
                event: { $in: await Event.find({ isDeleted: true }).distinct('_id') }
            });

            // D·ªçn d·∫πp notifications c≈©
            const Notification = require('../models/Notification');
            const oldNotifications = await Notification.deleteMany({
                $or: [
                    { isDeleted: true, deletedAt: { $lt: cutoffTime } },
                    { createdAt: { $lt: new Date(Date.now() - 90 * TIME_CONSTANTS.DAY) }, isRead: true }
                ]
            });

            // D·ªçn d·∫πp email queue c≈©
            const EmailQueue = require('../models/EmailQueue');
            const oldEmails = await EmailQueue.deleteMany({
                $or: [
                    { status: 'sent', sentAt: { $lt: cutoffTime } },
                    { status: 'failed_permanent', failedAt: { $lt: cutoffTime } }
                ]
            });

            logger.info(`ƒê√£ d·ªçn d·∫πp: ${deletedEvents.deletedCount} events, ${deletedUsers.deletedCount} users, ${orphanedRegistrations.deletedCount} registrations, ${oldNotifications.deletedCount} notifications, ${oldEmails.deletedCount} emails`);

        } catch (error) {
            logger.error('D·ªçn d·∫πp soft deleted data th·∫•t b·∫°i:', error);
        } finally {
            this.isRunning = false;
        }
    }

    /**
     * D·ªçn d·∫πp Redis cache
     */
    async cleanupRedisCache() {
        try {
            logger.info('B·∫Øt ƒë·∫ßu d·ªçn d·∫πp Redis cache...');

            let deletedKeys = 0;

            // D·ªçn d·∫πp cache h·∫øt h·∫°n
            const expiredPatterns = [
                'cache:*',
                'session:*',
                'rate_limit:*',
                'temp:*'
            ];

            for (const pattern of expiredPatterns) {
                try {
                    const keys = await redisClient.keys(pattern);

                    for (const key of keys) {
                        const ttl = await redisClient.ttl(key);

                        // X√≥a key h·∫øt h·∫°n ho·∫∑c kh√¥ng c√≥ TTL v√† t·∫°o t·ª´ l√¢u
                        if (ttl === -1 || ttl === 0) {
                            const keyAge = await this.getRedisKeyAge(key);
                            if (keyAge > 24 * 60 * 60) { // H∆°n 24 gi·ªù
                                await redisClient.del(key);
                                deletedKeys++;
                            }
                        }
                    }
                } catch (error) {
                    logger.warn(`L·ªói d·ªçn d·∫πp pattern ${pattern}:`, error.message);
                }
            }

            // D·ªçn d·∫πp rate limit violations c≈©
            const violationKeys = await redisClient.keys('violations:*');
            for (const key of violationKeys) {
                const ttl = await redisClient.ttl(key);
                if (ttl <= 0) {
                    await redisClient.del(key);
                    deletedKeys++;
                }
            }

            // T·ªëi ∆∞u Redis memory
            if (deletedKeys > 100) {
                await redisClient.flushdb(); // Ch·ªâ flush n·∫øu c√≥ nhi·ªÅu key c·∫ßn x√≥a
                logger.info('ƒê√£ flush Redis database ƒë·ªÉ t·ªëi ∆∞u memory');
            }

            logger.info(`ƒê√£ d·ªçn d·∫πp ${deletedKeys} Redis keys`);

        } catch (error) {
            logger.error('D·ªçn d·∫πp Redis cache th·∫•t b·∫°i:', error);
        }
    }

    /**
     * D·ªçn d·∫πp file uploads kh√¥ng s·ª≠ d·ª•ng
     */
    async cleanupOrphanedFiles() {
        try {
            logger.info('B·∫Øt ƒë·∫ßu t√¨m v√† d·ªçn d·∫πp orphaned files...');

            const uploadDirs = [
                './uploads/avatars',
                './uploads/events',
                './uploads/documents',
                './uploads/certificates'
            ];

            let totalDeleted = 0;
            let totalSize = 0;

            for (const uploadDir of uploadDirs) {
                try {
                    await fs.access(uploadDir);
                    const { deleted, size } = await this.findAndCleanOrphanedFiles(uploadDir);
                    totalDeleted += deleted;
                    totalSize += size;
                } catch (error) {
                    if (error.code !== 'ENOENT') {
                        logger.warn(`Kh√¥ng th·ªÉ truy c·∫≠p ${uploadDir}:`, error.message);
                    }
                }
            }

            logger.info(`ƒê√£ d·ªçn d·∫πp ${totalDeleted} orphaned files, gi·∫£i ph√≥ng ${this.formatBytes(totalSize)}`);

        } catch (error) {
            logger.error('D·ªçn d·∫πp orphaned files th·∫•t b·∫°i:', error);
        }
    }

    /**
     * D·ªçn d·∫πp analytics data c≈©
     */
    async cleanupOldAnalytics() {
        try {
            logger.info('B·∫Øt ƒë·∫ßu d·ªçn d·∫πp analytics data c≈©...');

            const cutoffTime = new Date(Date.now() - (this.cleanupConfig.analyticsRetentionDays * TIME_CONSTANTS.DAY));

            // D·ªçn d·∫πp page views c≈©
            const PageView = require('../models/PageView');
            const oldPageViews = await PageView.deleteMany({
                createdAt: { $lt: cutoffTime }
            });

            // D·ªçn d·∫πp search queries c≈©
            const SearchQuery = require('../models/SearchQuery');
            const oldSearches = await SearchQuery.deleteMany({
                createdAt: { $lt: cutoffTime }
            });

            // D·ªçn d·∫πp event analytics c≈© (gi·ªØ l·∫°i summary)
            const EventAnalytics = require('../models/EventAnalytics');
            const oldEventAnalytics = await EventAnalytics.deleteMany({
                createdAt: { $lt: cutoffTime },
                type: 'detailed' // Ch·ªâ x√≥a detailed, gi·ªØ summary
            });

            // Archive old analytics thay v√¨ x√≥a
            await this.archiveOldAnalytics(cutoffTime);

            logger.info(`ƒê√£ d·ªçn d·∫πp ${oldPageViews.deletedCount} page views, ${oldSearches.deletedCount} searches, ${oldEventAnalytics.deletedCount} event analytics`);

        } catch (error) {
            logger.error('D·ªçn d·∫πp analytics data th·∫•t b·∫°i:', error);
        }
    }

    /**
     * T·ªëi ∆∞u database
     */
    async optimizeDatabase() {
        if (this.isRunning) return;
        this.isRunning = true;

        try {
            logger.info('B·∫Øt ƒë·∫ßu t·ªëi ∆∞u database...');

            const db = mongoose.connection.db;
            const collections = await db.listCollections().toArray();

            let optimizedCollections = 0;

            for (const collection of collections) {
                try {
                    const collectionName = collection.name;

                    // Reindex collection
                    await db.collection(collectionName).reIndex();

                    // Compact collection (MongoDB 4.4+)
                    try {
                        await db.runCommand({ compact: collectionName });
                    } catch (compactError) {
                        // Compact kh√¥ng kh·∫£ d·ª•ng tr√™n m·ªçi setup
                        logger.debug(`Compact kh√¥ng kh·∫£ d·ª•ng cho ${collectionName}`);
                    }

                    optimizedCollections++;

                    // Delay ng·∫Øn gi·ªØa c√°c collection
                    await this.sleep(100);

                } catch (error) {
                    logger.warn(`L·ªói t·ªëi ∆∞u collection ${collection.name}:`, error.message);
                }
            }

            // C·∫≠p nh·∫≠t statistics
            await db.runCommand({ planCacheClear: 1 });

            logger.info(`ƒê√£ t·ªëi ∆∞u ${optimizedCollections} collections`);

        } catch (error) {
            logger.error('T·ªëi ∆∞u database th·∫•t b·∫°i:', error);
        } finally {
            this.isRunning = false;
        }
    }

    /**
     * D·ªçn d·∫πp th∆∞ m·ª•c
     */
    async cleanupDirectory(dirPath, cutoffTime, filePattern = null) {
        let deletedCount = 0;
        let totalSize = 0;

        try {
            const files = await fs.readdir(dirPath);

            for (const file of files) {
                const filePath = path.join(dirPath, file);

                try {
                    const stats = await fs.stat(filePath);

                    // Ki·ªÉm tra pattern n·∫øu c√≥
                    if (filePattern && !filePattern.test(file)) {
                        continue;
                    }

                    if (stats.isFile() && stats.mtime.getTime() < cutoffTime) {
                        totalSize += stats.size;
                        await fs.unlink(filePath);
                        deletedCount++;
                    } else if (stats.isDirectory()) {
                        // Recursively clean subdirectories
                        const { deleted, size } = await this.cleanupDirectory(filePath, cutoffTime, filePattern);
                        deletedCount += deleted;
                        totalSize += size;

                        // X√≥a th∆∞ m·ª•c r·ªóng
                        try {
                            const remainingFiles = await fs.readdir(filePath);
                            if (remainingFiles.length === 0) {
                                await fs.rmdir(filePath);
                            }
                        } catch (error) {
                            // Th∆∞ m·ª•c kh√¥ng r·ªóng ho·∫∑c l·ªói kh√°c
                        }
                    }
                } catch (error) {
                    logger.warn(`L·ªói x·ª≠ l√Ω file ${filePath}:`, error.message);
                }
            }

        } catch (error) {
            logger.error(`L·ªói d·ªçn d·∫πp th∆∞ m·ª•c ${dirPath}:`, error);
        }

        return { deleted: deletedCount, size: totalSize };
    }

    /**
     * T√¨m v√† d·ªçn d·∫πp orphaned files
     */
    async findAndCleanOrphanedFiles(uploadDir) {
        let deletedCount = 0;
        let totalSize = 0;

        try {
            const files = await fs.readdir(uploadDir);

            for (const file of files) {
                const filePath = path.join(uploadDir, file);

                try {
                    const stats = await fs.stat(filePath);
                    if (!stats.isFile()) continue;

                    const isOrphaned = await this.isFileOrphaned(file, uploadDir);

                    if (isOrphaned) {
                        // Ki·ªÉm tra tu·ªïi file tr∆∞·ªõc khi x√≥a (an to√†n)
                        const fileAge = Date.now() - stats.mtime.getTime();
                        if (fileAge > 24 * TIME_CONSTANTS.HOUR) { // File c≈© h∆°n 24 gi·ªù
                            totalSize += stats.size;
                            await fs.unlink(filePath);
                            deletedCount++;

                            logger.debug(`ƒê√£ x√≥a orphaned file: ${file}`);
                        }
                    }
                } catch (error) {
                    logger.warn(`L·ªói ki·ªÉm tra file ${file}:`, error.message);
                }
            }

        } catch (error) {
            logger.error(`L·ªói d·ªçn d·∫πp orphaned files trong ${uploadDir}:`, error);
        }

        return { deleted: deletedCount, size: totalSize };
    }

    /**
     * Ki·ªÉm tra file c√≥ ph·∫£i orphaned kh√¥ng
     */
    async isFileOrphaned(filename, uploadDir) {
        try {
            // Ki·ªÉm tra trong database models kh√°c nhau
            const checks = [];

            if (uploadDir.includes('avatars')) {
                const User = require('../models/User');
                checks.push(User.findOne({ 'profile.avatar': filename }));
            }

            if (uploadDir.includes('events')) {
                const Event = require('../models/Event');
                checks.push(Event.findOne({
                    $or: [
                        { 'media.banner': filename },
                        { 'media.images': filename },
                        { 'media.documents': filename }
                    ]
                }));
            }

            if (uploadDir.includes('certificates')) {
                const Certificate = require('../models/Certificate');
                checks.push(Certificate.findOne({ filePath: filename }));
            }

            const results = await Promise.all(checks);
            return results.every(result => result === null);

        } catch (error) {
            logger.error(`L·ªói ki·ªÉm tra orphaned file ${filename}:`, error);
            return false; // An to√†n - kh√¥ng x√≥a n·∫øu kh√¥ng ch·∫Øc ch·∫Øn
        }
    }

    /**
     * Archive analytics data c≈©
     */
    async archiveOldAnalytics(cutoffTime) {
        try {
            const Analytics = require('../models/Analytics');

            // T·∫°o summary data t·ª´ detailed data c≈©
            const oldAnalytics = await Analytics.find({
                createdAt: { $lt: cutoffTime },
                type: 'detailed'
            });

            if (oldAnalytics.length > 0) {
                // Group by month v√† t·∫°o summary
                const monthlyGroups = {};

                oldAnalytics.forEach(item => {
                    const monthKey = item.createdAt.toISOString().substring(0, 7); // YYYY-MM
                    if (!monthlyGroups[monthKey]) {
                        monthlyGroups[monthKey] = [];
                    }
                    monthlyGroups[monthKey].push(item);
                });

                // T·∫°o monthly summaries
                for (const [month, items] of Object.entries(monthlyGroups)) {
                    const summary = this.createMonthlySummary(items);

                    const AnalyticsSummary = require('../models/AnalyticsSummary');
                    await AnalyticsSummary.findOneAndUpdate(
                        { month },
                        { ...summary, month },
                        { upsert: true }
                    );
                }

                // X√≥a detailed data sau khi archive
                await Analytics.deleteMany({
                    createdAt: { $lt: cutoffTime },
                    type: 'detailed'
                });

                logger.info(`ƒê√£ archive ${oldAnalytics.length} analytics records th√†nh ${Object.keys(monthlyGroups).length
                } monthly summaries`);
            }

        } catch (error) {
            logger.error('Archive analytics th·∫•t b·∫°i:', error);
        }
    }

    /**
     * T·∫°o monthly summary t·ª´ detailed data
     */
    createMonthlySummary(items) {
        const summary = {
            totalEvents: 0,
            totalRegistrations: 0,
            totalUsers: 0,
            totalPageViews: 0,
            avgSessionDuration: 0,
            topEventTypes: {},
            topCategories: {},
            greater_equal
        };

        items.forEach(item => {
            if (item.events) summary.totalEvents += item.events;
            if (item.registrations) summary.totalRegistrations += item.registrations;
            if (item.users) summary.totalUsers += item.users;
            if (item.pageViews) summary.totalPageViews += item.pageViews;

            // Aggregate other metrics
            if (item.eventTypes) {
                Object.entries(item.eventTypes).forEach(([type, count]) => {
                    summary.topEventTypes[type] = (summary.topEventTypes[type] || 0) + count;
                });
            }
        });

        // T√≠nh average
        if (items.length > 0) {
            summary.avgSessionDuration = items.reduce((sum, item) =>
                sum + (item.avgSessionDuration || 0), 0) / items.length;
        }

        return summary;
    }

    /**
     * L·∫•y tu·ªïi c·ªßa Redis key
     */
    async getRedisKeyAge(key) {
        try {
            // Gi·∫£ s·ª≠ key c√≥ timestamp trong t√™n ho·∫∑c d√πng OBJECT IDLETIME
            const idleTime = await redisClient.object('IDLETIME', key);
            return idleTime || 0;
        } catch (error) {
            return 0;
        }
    }

    /**
     * D·ªçn d·∫πp error logs ƒë√£ resolved
     */
    async cleanupResolvedErrors() {
        try {
            const ErrorLog = require('../models/ErrorLog');
            const cutoffTime = new Date(Date.now() - (30 * TIME_CONSTANTS.DAY)); // 30 ng√†y

            const deletedErrors = await ErrorLog.deleteMany({
                resolved: true,
                resolvedAt: { $lt: cutoffTime }
            });

            logger.info(`ƒê√£ d·ªçn d·∫πp ${deletedErrors.deletedCount} error logs ƒë√£ resolved`);

        } catch (error) {
            logger.error('D·ªçn d·∫πp error logs th·∫•t b·∫°i:', error);
        }
    }

    /**
     * D·ªçn d·∫πp audit logs c≈©
     */
    async cleanupOldAuditLogs() {
        try {
            const AuditLog = require('../models/AuditLog');
            const cutoffTime = new Date(Date.now() - (365 * TIME_CONSTANTS.DAY)); // 1 nƒÉm

            // Archive audit logs thay v√¨ x√≥a
            const oldLogs = await AuditLog.find({
                createdAt: { $lt: cutoffTime }
            });

            if (oldLogs.length > 0) {
                // T·∫°o archive file
                const archivePath = path.join('./archives', `audit-logs-${new Date().getFullYear()}.json`);
                await fs.mkdir('./archives', { recursive: true });
                await fs.writeFile(archivePath, JSON.stringify(oldLogs, null, 2));

                // X√≥a t·ª´ database
                const deleted = await AuditLog.deleteMany({
                    createdAt: { $lt: cutoffTime }
                });

                logger.info(`ƒê√£ archive ${deleted.deletedCount} audit logs c≈©`);
            }

        } catch (error) {
            logger.error('D·ªçn d·∫πp audit logs th·∫•t b·∫°i:', error);
        }
    }

    /**
     * Cleanup job to√†n di·ªán
     */
    async performFullCleanup() {
        if (this.isRunning) {
            logger.warn('Cleanup ƒëang ch·∫°y, b·ªè qua full cleanup');
            return;
        }

        this.isRunning = true;

        try {
            logger.info('B·∫Øt ƒë·∫ßu full system cleanup...');

            const startTime = Date.now();
            const results = {};

            // Th·ª±c hi·ªán t·∫•t c·∫£ cleanup tasks
            results.tempFiles = await this.cleanupTempFiles();
            results.sessions = await this.cleanupExpiredSessions();
            results.logs = await this.cleanupOldLogs();
            results.softDeleted = await this.cleanupSoftDeletedData();
            results.redis = await this.cleanupRedisCache();
            results.orphanedFiles = await this.cleanupOrphanedFiles();
            results.analytics = await this.cleanupOldAnalytics();
            results.errors = await this.cleanupResolvedErrors();
            results.auditLogs = await this.cleanupOldAuditLogs();

            // Optimize database
            await this.optimizeDatabase();

            const duration = Date.now() - startTime;
            logger.info(`Full cleanup ho√†n th√†nh trong ${duration}ms`, results);

            // G·ª≠i b√°o c√°o cleanup cho admin
            await this.sendCleanupReport(results, duration);

        } catch (error) {
            logger.error('Full cleanup th·∫•t b·∫°i:', error);
        } finally {
            this.isRunning = false;
        }
    }

    /**
     * G·ª≠i b√°o c√°o cleanup
     */
    async sendCleanupReport(results, duration) {
        try {
            const User = require('../models/User');
            const admins = await User.find({
                roles: 'admin',
                'preferences.notifications.systemReports': true,
                isActive: true
            });

            const reportContent = this.generateCleanupReportContent(results, duration);

            for (const admin of admins) {
                await emailService.sendEmail({
                    to: admin.email,
                    subject: `üßπ B√°o c√°o System Cleanup - ${new Date().toLocaleDateString('vi-VN')}`,
                    html: reportContent
                });
            }

        } catch (error) {
            logger.error('G·ª≠i cleanup report th·∫•t b·∫°i:', error);
        }
    }

    /**
     * T·∫°o n·ªôi dung b√°o c√°o cleanup
     */
    generateCleanupReportContent(results, duration) {
        return `
            <div style="font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto;">
                <h2>üßπ B√°o c√°o System Cleanup</h2>
                <p><strong>Th·ªùi gian th·ª±c hi·ªán:</strong> ${new Date().toLocaleString('vi-VN')}</p>
                <p><strong>Th·ªùi gian x·ª≠ l√Ω:</strong> ${Math.round(duration / 1000)} gi√¢y</p>
                
                <div style="background-color: #f8f9fa; padding: 20px; border-radius: 10px; margin: 20px 0;">
                    <h3>üìä K·∫øt qu·∫£ Cleanup</h3>
                    <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px;">
                        ${Object.entries(results).filter(([key, value]) => value && typeof value === 'object').map(([key, value]) => `
                            <div style="background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                                <h4 style="margin-top: 0; color: #007bff;">${key.replace(/([A-Z])/g, ' $1').trim()}</h4>
                                ${Object.entries(value).map(([subKey, subValue]) => `
                                    <p style="margin: 5px 0;"><strong>${subKey}:</strong> ${subValue}</p>
                                `).join('')}
                            </div>
                        `).join('')}
                    </div>
                </div>
                
                <div style="background-color: #d1ecf1; padding: 15px; border-radius: 8px; margin: 20px 0;">
                    <p><strong>üí° Ghi ch√∫:</strong> Cleanup ƒë∆∞·ª£c th·ª±c hi·ªán t·ª± ƒë·ªông ƒë·ªÉ duy tr√¨ hi·ªáu su·∫•t h·ªá th·ªëng t·ªët nh·∫•t.</p>
                    <p>N·∫øu c√≥ v·∫•n ƒë·ªÅ g√¨, vui l√≤ng ki·ªÉm tra system logs ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt.</p>
                </div>
            </div>
        `;
    }

    /**
     * Cleanup cache theo pattern
     */
    async cleanupCacheByPattern(pattern, maxAge = 24 * TIME_CONSTANTS.HOUR) {
        try {
            const keys = await redisClient.keys(pattern);
            let deletedCount = 0;

            for (const key of keys) {
                try {
                    const ttl = await redisClient.ttl(key);
                    const keyAge = await this.getRedisKeyAge(key);

                    if (ttl === -1 && keyAge > maxAge) {
                        await redisClient.del(key);
                        deletedCount++;
                    }
                } catch (error) {
                    logger.warn(`L·ªói cleanup cache key ${key}:`, error.message);
                }
            }

            logger.info(`ƒê√£ x√≥a ${deletedCount} keys theo pattern ${pattern}`);
            return deletedCount;
        } catch (error) {
            logger.error(`Cleanup cache pattern ${pattern} th·∫•t b·∫°i:`, error);
            return 0;
        }
    }

    /**
     * D·ªçn d·∫πp upload thumbnails kh√¥ng s·ª≠ d·ª•ng
     */
    async cleanupUnusedThumbnails() {
        try {
            const thumbnailDir = './uploads/thumbnails';
            await fs.access(thumbnailDir);

            const files = await fs.readdir(thumbnailDir);
            let deletedCount = 0;
            let totalSize = 0;

            for (const file of files) {
                if (!file.includes('_thumb.')) continue;

                const originalFile = file.replace('_thumb.', '.');
                const originalPath = path.join('./uploads', originalFile);

                try {
                    await fs.access(originalPath);
                } catch (error) {
                    // Original file kh√¥ng t·ªìn t·∫°i, x√≥a thumbnail
                    const thumbnailPath = path.join(thumbnailDir, file);
                    const stats = await fs.stat(thumbnailPath);
                    totalSize += stats.size;
                    await fs.unlink(thumbnailPath);
                    deletedCount++;
                }
            }

            if (deletedCount > 0) {
                logger.info(`ƒê√£ d·ªçn d·∫πp ${deletedCount} unused thumbnails, gi·∫£i ph√≥ng ${this.formatBytes(totalSize)}`);
            }

        } catch (error) {
            if (error.code !== 'ENOENT') {
                logger.error('Cleanup thumbnails th·∫•t b·∫°i:', error);
            }
        }
    }

    /**
     * D·ªçn d·∫πp database indexes kh√¥ng s·ª≠ d·ª•ng
     */
    async cleanupUnusedIndexes() {
        try {
            const db = mongoose.connection.db;
            const collections = await db.listCollections().toArray();

            for (const collection of collections) {
                try {
                    const collectionName = collection.name;
                    const indexes = await db.collection(collectionName).indexes();

                    // L·∫•y index usage stats (MongoDB 3.2+)
                    try {
                        const stats = await db.collection(collectionName).aggregate([
                            { $indexStats: {} }
                        ]).toArray();

                        for (const indexStat of stats) {
                            // N·∫øu index kh√¥ng ƒë∆∞·ª£c s·ª≠ d·ª•ng trong 30 ng√†y v√† kh√¥ng ph·∫£i _id
                            if (indexStat.name !== '_id_' &&
                                indexStat.accesses.ops === 0 &&
                                indexStat.accesses.since) {

                                const daysSinceCreated = (Date.now() - new Date(indexStat.accesses.since)) / TIME_CONSTANTS.DAY;

                                if (daysSinceCreated > 30) {
                                    logger.warn(`Index ${indexStat.name} tr√™n ${collectionName} kh√¥ng ƒë∆∞·ª£c s·ª≠ d·ª•ng trong 30 ng√†y`);
                                    // C√≥ th·ªÉ drop index n·∫øu c·∫ßn (c·∫©n tr·ªçng)
                                    // await db.collection(collectionName).dropIndex(indexStat.name);
                                }
                            }
                        }
                    } catch (statsError) {
                        // $indexStats kh√¥ng kh·∫£ d·ª•ng tr√™n version c≈©
                    }

                } catch (error) {
                    logger.warn(`L·ªói ki·ªÉm tra indexes cho ${collection.name}:`, error.message);
                }
            }

        } catch (error) {
            logger.error('Cleanup unused indexes th·∫•t b·∫°i:', error);
        }
    }

    /**
     * Monitor v√† report disk usage
     */
    async monitorDiskUsage() {
        try {
            const { execSync } = require('child_process');

            // L·∫•y disk usage (Linux/Mac)
            try {
                const diskUsage = execSync('df -h /', { encoding: 'utf8' });
                const lines = diskUsage.split('\n');
                const dataLine = lines[1].split(/\s+/);
                const usagePercent = parseInt(dataLine[4]);

                if (usagePercent > 85) {
                    logger.warn(`Disk usage cao: ${usagePercent}%`);

                    // G·ª≠i c·∫£nh b√°o
                    await this.sendDiskUsageAlert(usagePercent);

                    // Th·ª±c hi·ªán emergency cleanup
                    await this.emergencyCleanup();
                }

            } catch (error) {
                // Fallback cho Windows ho·∫∑c l·ªói command
                logger.debug('Kh√¥ng th·ªÉ l·∫•y disk usage:', error.message);
            }

        } catch (error) {
            logger.error('Monitor disk usage th·∫•t b·∫°i:', error);
        }
    }

    /**
     * Emergency cleanup khi disk ƒë·∫ßy
     */
    async emergencyCleanup() {
        try {
            logger.warn('Th·ª±c hi·ªán emergency cleanup do disk usage cao...');

            // D·ªçn d·∫πp aggressive h∆°n
            await this.cleanupTempFiles();
            await this.cleanupRedisCache();

            // X√≥a logs c≈© h∆°n 7 ng√†y
            const emergencyCutoff = Date.now() - (7 * TIME_CONSTANTS.DAY);
            await this.cleanupDirectory('./logs', emergencyCutoff);

            // Compress logs c≈© thay v√¨ x√≥a
            await this.compressOldLogs();

        } catch (error) {
            logger.error('Emergency cleanup th·∫•t b·∫°i:', error);
        }
    }

    /**
     * Compress logs c≈©
     */
    async compressOldLogs() {
        try {
            const zlib = require('zlib');
            const logDir = './logs';

            const files = await fs.readdir(logDir);
            const cutoffTime = Date.now() - (7 * TIME_CONSTANTS.DAY);

            for (const file of files) {
                if (!file.endsWith('.log') || file.endsWith('.gz')) continue;

                const filePath = path.join(logDir, file);
                const stats = await fs.stat(filePath);

                if (stats.mtime.getTime() < cutoffTime) {
                    // Compress file
                    const compressedPath = `${filePath}.gz`;
                    const readStream = require('fs').createReadStream(filePath);
                    const writeStream = require('fs').createWriteStream(compressedPath);
                    const gzip = zlib.createGzip();

                    await new Promise((resolve, reject) => {
                        readStream.pipe(gzip).pipe(writeStream)
                            .on('finish', resolve)
                            .on('error', reject);
                    });

                    // X√≥a file g·ªëc
                    await fs.unlink(filePath);
                    logger.debug(`ƒê√£ compress log file: ${file}`);
                }
            }

        } catch (error) {
            logger.error('Compress logs th·∫•t b·∫°i:', error);
        }
    }

    /**
     * G·ª≠i c·∫£nh b√°o disk usage
     */
    async sendDiskUsageAlert(usagePercent) {
        try {
            const emailService = require('../config/email');
            const adminEmails = process.env.ADMIN_EMAILS?.split(',') || [];

            for (const email of adminEmails) {
                await emailService.sendEmail({
                    to: email.trim(),
                    subject: `‚ö†Ô∏è C·∫£nh b√°o: Disk Usage cao (${usagePercent}%)`,
                    html: `
                        <div style="font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto;">
                            <div style="background-color: #fff3cd; border-left: 4px solid #ffc107; padding: 15px; margin: 20px 0;">
                                <h3 style="color: #856404; margin-top: 0;">‚ö†Ô∏è C·∫£nh b√°o Disk Usage</h3>
                                <p>Disk usage hi·ªán t·∫°i: <strong>${usagePercent}%</strong></p>
                                <p>H·ªá th·ªëng ƒë√£ t·ª± ƒë·ªông th·ª±c hi·ªán emergency cleanup.</p>
                                <p>Vui l√≤ng ki·ªÉm tra v√† gi·∫£i ph√≥ng th√™m dung l∆∞·ª£ng n·∫øu c·∫ßn thi·∫øt.</p>
                            </div>
                        </div>
                    `
                });
            }
        } catch (error) {
            logger.error('G·ª≠i disk usage alert th·∫•t b·∫°i:', error);
        }
    }

    // Helper methods
    formatBytes(bytes) {
        const sizes = ['Bytes', 'KB', 'MB', 'GB', 'TB'];
        if (bytes === 0) return '0 Byte';
        const i = parseInt(Math.floor(Math.log(bytes) / Math.log(1024)));
        return Math.round(bytes / Math.pow(1024, i), 2) + ' ' + sizes[i];
    }

    sleep(ms) {
        return new Promise(resolve => setTimeout(resolve, ms));
    }

    /**
     * L·∫•y tr·∫°ng th√°i cleanup jobs
     */
    getStatus() {
        return {
            isRunning: this.isRunning,
            config: this.cleanupConfig,
            nextRuns: {
                tempFiles: 'M·ªói gi·ªù',
                sessions: 'M·ªói 6 gi·ªù',
                logs: 'H√†ng ng√†y l√∫c 1:00',
                softDeleted: 'Ch·ªß nh·∫≠t l√∫c 2:00',
                redis: 'H√†ng ng√†y l√∫c 3:00',
                orphanedFiles: 'Ch·ªß nh·∫≠t l√∫c 4:00',
                analytics: 'Ng√†y 1 h√†ng th√°ng l√∫c 5:00',
                optimization: 'Ch·ªß nh·∫≠t l√∫c 6:00'
            }
        };
    }

    /**
     * Th·ª±c hi·ªán manual cleanup
     */
    async performManualCleanup(type, options = {}) {
        if (this.isRunning) {
            throw new Error('Cleanup job ƒëang ch·∫°y, vui l√≤ng ƒë·ª£i');
        }

        try {
            switch (type) {
                case 'temp':
                    return await this.cleanupTempFiles();
                case 'sessions':
                    return await this.cleanupExpiredSessions();
                case 'logs':
                    return await this.cleanupOldLogs();
                case 'redis':
                    return await this.cleanupRedisCache();
                case 'files':
                    return await this.cleanupOrphanedFiles();
                case 'analytics':
                    return await this.cleanupOldAnalytics();
                case 'full':
                    return await this.performFullCleanup();
                default:
                    throw new Error(`Lo·∫°i cleanup kh√¥ng h·ªó tr·ª£: ${type}`);
            }
        } catch (error) {
            logger.error(`Manual cleanup ${type} th·∫•t b·∫°i:`, error);
            throw error;
        }
    }

    /**
     * T√≠nh to√°n storage statistics
     */
    async getStorageStats() {
        try {
            const dirs = [
                { name: 'uploads', path: './uploads' },
                { name: 'logs', path: './logs' },
                { name: 'reports', path: './reports' },
                { name: 'backups', path: './backups' },
                { name: 'temp', path: './temp' }
            ];

            const stats = {};

            for (const dir of dirs) {
                try {
                    const dirStats = await this.calculateDirectorySize(dir.path);
                    stats[dir.name] = {
                        size: dirStats.size,
                        files: dirStats.files,
                        formattedSize: this.formatBytes(dirStats.size)
                    };
                } catch (error) {
                    stats[dir.name] = { size: 0, files: 0, formattedSize: '0 Bytes', error: error.message };
                }
            }

            return stats;
        } catch (error) {
            logger.error('L·∫•y storage stats th·∫•t b·∫°i:', error);
            return {};
        }
    }

    /**
     * T√≠nh k√≠ch th∆∞·ªõc th∆∞ m·ª•c
     */
    async calculateDirectorySize(dirPath) {
        let totalSize = 0;
        let fileCount = 0;

        const calculateSize = async (currentPath) => {
            try {
                const items = await fs.readdir(currentPath);

                for (const item of items) {
                    const itemPath = path.join(currentPath, item);
                    const stats = await fs.stat(itemPath);

                    if (stats.isDirectory()) {
                        await calculateSize(itemPath);
                    } else {
                        totalSize += stats.size;
                        fileCount++;
                    }
                }
            } catch (error) {
                // B·ªè qua l·ªói truy c·∫≠p
            }
        };

        await calculateSize(dirPath);
        return { size: totalSize, files: fileCount };
    }

    /**
     * Cleanup job health check
     */
    async healthCheck() {
        try {
            const health = {
                status: 'healthy',
                lastRun: new Date().toISOString(),
                checks: {
                    tempFiles: await this.checkTempFilesHealth(),
                    database: await this.checkDatabaseHealth(),
                    redis: await this.checkRedisHealth(),
                    storage: await this.checkStorageHealth()
                }
            };

            // Ki·ªÉm tra overall health
            const failedChecks = Object.values(health.checks).filter(check => !check.healthy);
            if (failedChecks.length > 0) {
                health.status = 'degraded';
            }

            return health;
        } catch (error) {
            logger.error('Cleanup health check th·∫•t b·∫°i:', error);
            return {
                status: 'unhealthy',
                error: error.message
            };
        }
    }

    async checkTempFilesHealth() {
        try {
            const tempDirs = ['./uploads/temp', './temp'];
            let totalFiles = 0;

            for (const dir of tempDirs) {
                try {
                    const files = await fs.readdir(dir);
                    totalFiles += files.length;
                } catch (error) {
                    // Directory kh√¥ng t·ªìn t·∫°i
                }
            }

            return {
                healthy: totalFiles < 1000,
                details: { tempFiles: totalFiles },
                message: totalFiles >= 1000 ? 'Qu√° nhi·ªÅu file t·∫°m' : 'OK'
            };
        } catch (error) {
            return { healthy: false, error: error.message };
        }
    }

    async checkDatabaseHealth() {
        try {
            const db = mongoose.connection.db;
            const stats = await db.stats();

            return {
                healthy: stats.ok === 1,
                details: {
                    collections: stats.collections,
                    dataSize: this.formatBytes(stats.dataSize),
                    storageSize: this.formatBytes(stats.storageSize)
                },
                message: 'Database OK'
            };
        } catch (error) {
            return { healthy: false, error: error.message };
        }
    }

    async checkRedisHealth() {
        try {
            const info = await redisClient.info('memory');
            const usedMemory = parseInt(info.match(/used_memory:(\d+)/)?.[1] || 0);
            const maxMemory = parseInt(info.match(/maxmemory:(\d+)/)?.[1] || 0);

            const usage = maxMemory > 0 ? (usedMemory / maxMemory) * 100 : 0;

            return {
                healthy: usage < 80,
                details: {
                    usedMemory: this.formatBytes(usedMemory),
                    usage: `${usage.toFixed(2)}%`
                },
                message: usage >= 80 ? 'Redis memory usage cao' : 'Redis OK'
            };
        } catch (error) {
            return { healthy: false, error: error.message };
        }
    }

    async checkStorageHealth() {
        try {
            const storageStats = await this.getStorageStats();
            const totalSize = Object.values(storageStats).reduce((sum, stat) => sum + stat.size, 0);

            // C·∫£nh b√°o n·∫øu storage > 5GB
            const warningSize = 5 * 1024 * 1024 * 1024; // 5GB

            return {
                healthy: totalSize < warningSize,
                details: {
                    totalSize: this.formatBytes(totalSize),
                    breakdown: storageStats
                },
                message: totalSize >= warningSize ? 'Storage usage cao' : 'Storage OK'
            };
        } catch (error) {
            return { healthy: false, error: error.message };
        }
    }
}

module.exports = new CleanupJobs();